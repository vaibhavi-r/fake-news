{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from time import time\n",
    "import string\n",
    "#import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#from gensim import models\n",
    "#from gensim.models import word2vec,doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/fake_or_real_news.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "Unnamed: 0                                                      \n",
       "8476                             You Can Smell Hillary’s Fear   \n",
       "10294       Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608              Kerry to go to Paris in gesture of sympathy   \n",
       "10142       Bernie supporters on Twitter erupt in anger ag...   \n",
       "875          The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                         text label  \n",
       "Unnamed: 0                                                           \n",
       "8476        Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294       Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608        U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142       — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875         It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set index\n",
    "df = df.set_index('Unnamed: 0') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "docId                                                      \n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label  \n",
       "docId                                                           \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875    It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename index\n",
    "df.index.names = ['docId']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process  : Article text & title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuart 3 potato bake'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Punctuation\n",
    "# Convert to Lowercase\n",
    "# Stem words\n",
    "# Remove Numbers\n",
    "# Remove Stop Words\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    return s\n",
    "\n",
    "def preprocess_string(s):\n",
    "    s = remove_punctuation(s)\n",
    "    s= s.lower()\n",
    "    \n",
    "    #tokenize\n",
    "    words = word_tokenize(s)\n",
    "\n",
    "    #unique words\n",
    "    words = list(set(words))\n",
    "\n",
    "    #stem\n",
    "    ps = PorterStemmer()    \n",
    "    words = [ps.stem(w) for w in words]\n",
    "    \n",
    "    #stopwords\n",
    "    STOP_WORDS = list(stopwords.words('english'))         #About 900 stopwords\n",
    "    words = [w for w in words if not w in STOP_WORDS]\n",
    "\n",
    "    #recombine words\n",
    "    s = ' '.join(words)\n",
    "    \n",
    "    #regex remove numbers\n",
    "    #RE_PREPROCESS = r'\\W+|\\d+' #the regular expressions that matches all non-characters\n",
    "    #s = re.sub(RE_PREPROCESS, ' ', s)\n",
    "    \n",
    "    #remove extra spaces\n",
    "    s = re.sub(' +',' ',s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "preprocess_string(\"Baked 3=$ ,Stuart's baked  M  Potatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df, input_col, output_col):\n",
    "    df[output_col] = df[input_col].apply(preprocess_string)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Preprocessing text is expected to take around 2-3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = preprocess_df(df, 'text', 'cleanText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = preprocess_df(df, 'title', 'cleanTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>cleanTitle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>bring knew done result store breath much lie n...</td>\n",
       "      <td>’ fear hillari smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>came print alreadi done day desper exampl limp...</td>\n",
       "      <td>polit suicid trump paul watch ralli video mome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>citi secur later note staffer taken attorney b...</td>\n",
       "      <td>gestur go kerri pari sympathi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>accord avoid post vote convent jill work dure ...</td>\n",
       "      <td>warn support tri anger erupt dnc berni twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>deleg victori point momentum watch convent fro...</td>\n",
       "      <td>york matter primari thi whi battl new</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "docId                                                      \n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label  \\\n",
       "docId                                                            \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "875    It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                               cleanText  \\\n",
       "docId                                                      \n",
       "8476   bring knew done result store breath much lie n...   \n",
       "10294  came print alreadi done day desper exampl limp...   \n",
       "3608   citi secur later note staffer taken attorney b...   \n",
       "10142  accord avoid post vote convent jill work dure ...   \n",
       "875    deleg victori point momentum watch convent fro...   \n",
       "\n",
       "                                              cleanTitle  \n",
       "docId                                                     \n",
       "8476                                ’ fear hillari smell  \n",
       "10294  polit suicid trump paul watch ralli video mome...  \n",
       "3608                       gestur go kerri pari sympathi  \n",
       "10142     warn support tri anger erupt dnc berni twitter  \n",
       "875                york matter primari thi whi battl new  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train-Test set from Article Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.label \n",
    "df.drop(\"label\", axis=1) \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleanText'], y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4244,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "docId\n",
      "4857    bring secur stake temperament gate affect illf...\n",
      "9885    declin came watch belong dure anoth new aid an...\n",
      "6681    accord personnel fals load friend result game ...\n",
      "9306    bring class fund veneer indic special design e...\n",
      "2232    egypt tripl painstakingli show magazin new tra...\n",
      "Name: cleanText, dtype: object\n",
      "(2091,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "docId\n",
      "9957    bring scandal fragment devour effect knew word...\n",
      "7596    accord came 3 appear result carolina attorney ...\n",
      "8905    accord bring 8th effect wish word 3 oppos done...\n",
      "8752    print individu earlier could octob 27 cnn trut...\n",
      "7804    later milk proceed attempt homicid fed 66 pour...\n",
      "Name: cleanText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(type(X_train))\n",
    "print(X_train.head())\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(type(X_test))\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Article Text (Bag of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english') \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4244, 50615)\n",
      "(2091, 50615)\n",
      "(4244, 50612)\n",
      "(2091, 50612)\n",
      "(4244, 1048576)\n",
      "(2091, 1048576)\n"
     ]
    }
   ],
   "source": [
    "print(count_train.shape)\n",
    "print(count_test.shape)\n",
    "\n",
    "print(tfidf_train.shape)\n",
    "print(tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['שתי', 'תאמצנה', 'תוצאה', 'תחל', 'תיירות', 'תנותק', 'תעודת', 'תתרכז', 'القادمون', 'عربي']\n",
      "['00', '000', '0000', '0000000031', '000000031', '00017b2908ff9fa45188d243fd49aaeeb2dhrcofficecom', '0004', '0006', '0007', '0008']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names()[-10:])\n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ha', 'thi', 'wa'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>0000000031</th>\n",
       "      <th>000000031</th>\n",
       "      <th>00017b2908ff9fa45188d243fd49aaeeb2dhrcofficecom</th>\n",
       "      <th>0004</th>\n",
       "      <th>0006</th>\n",
       "      <th>0007</th>\n",
       "      <th>0008</th>\n",
       "      <th>...</th>\n",
       "      <th>שתי</th>\n",
       "      <th>תאמצנה</th>\n",
       "      <th>תוצאה</th>\n",
       "      <th>תחל</th>\n",
       "      <th>תיירות</th>\n",
       "      <th>תנותק</th>\n",
       "      <th>תעודת</th>\n",
       "      <th>תתרכז</th>\n",
       "      <th>القادمون</th>\n",
       "      <th>عربي</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  0000000031  000000031  \\\n",
       "0  0.0  0.0   0.0         0.0        0.0   \n",
       "1  0.0  0.0   0.0         0.0        0.0   \n",
       "2  0.0  0.0   0.0         0.0        0.0   \n",
       "3  0.0  0.0   0.0         0.0        0.0   \n",
       "4  0.0  0.0   0.0         0.0        0.0   \n",
       "\n",
       "   00017b2908ff9fa45188d243fd49aaeeb2dhrcofficecom  0004  0006  0007  0008  \\\n",
       "0                                              0.0   0.0   0.0   0.0   0.0   \n",
       "1                                              0.0   0.0   0.0   0.0   0.0   \n",
       "2                                              0.0   0.0   0.0   0.0   0.0   \n",
       "3                                              0.0   0.0   0.0   0.0   0.0   \n",
       "4                                              0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   ...   שתי  תאמצנה  תוצאה  תחל  תיירות  תנותק  תעודת  תתרכז  القادمون  عربي  \n",
       "0  ...   0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   0.0  \n",
       "1  ...   0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   0.0  \n",
       "2  ...   0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   0.0  \n",
       "3  ...   0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   0.0  \n",
       "4  ...   0.0     0.0    0.0  0.0     0.0    0.0    0.0    0.0       0.0   0.0  \n",
       "\n",
       "[5 rows x 50612 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>0000000031</th>\n",
       "      <th>000000031</th>\n",
       "      <th>00017b2908ff9fa45188d243fd49aaeeb2dhrcofficecom</th>\n",
       "      <th>0004</th>\n",
       "      <th>0006</th>\n",
       "      <th>0007</th>\n",
       "      <th>0008</th>\n",
       "      <th>...</th>\n",
       "      <th>שתי</th>\n",
       "      <th>תאמצנה</th>\n",
       "      <th>תוצאה</th>\n",
       "      <th>תחל</th>\n",
       "      <th>תיירות</th>\n",
       "      <th>תנותק</th>\n",
       "      <th>תעודת</th>\n",
       "      <th>תתרכז</th>\n",
       "      <th>القادمون</th>\n",
       "      <th>عربي</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  0000000031  000000031  \\\n",
       "0   0    0     0           0          0   \n",
       "1   0    0     0           0          0   \n",
       "2   0    0     0           0          0   \n",
       "3   0    0     0           0          0   \n",
       "4   0    0     0           0          0   \n",
       "\n",
       "   00017b2908ff9fa45188d243fd49aaeeb2dhrcofficecom  0004  0006  0007  0008  \\\n",
       "0                                                0     0     0     0     0   \n",
       "1                                                0     0     0     0     0   \n",
       "2                                                0     0     0     0     0   \n",
       "3                                                0     0     0     0     0   \n",
       "4                                                0     0     0     0     0   \n",
       "\n",
       "   ...   שתי  תאמצנה  תוצאה  תחל  תיירות  תנותק  תעודת  תתרכז  القادمون  عربي  \n",
       "0  ...     0       0      0    0       0      0      0      0         0     0  \n",
       "1  ...     0       0      0    0       0      0      0      0         0     0  \n",
       "2  ...     0       0      0    0       0      0      0      0         0     0  \n",
       "3  ...     0       0      0    0       0      0      0      0         0     0  \n",
       "4  ...     0       0      0    0       0      0      0      0         0     0  \n",
       "\n",
       "[5 rows x 50615 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Article as Fake / Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: General Purpose Method to fit, classify and score a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_and_fit(clf, X_train, y_train, X_test, y_test, class_labels = ['FAKE', 'REAL']):\n",
    "    print(\"Classifier : \", clf )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    \n",
    "    print(\"Accuracy:   %0.3f\" % score)\n",
    "\n",
    "    print(\"\\nConfusion Matrix :\")\n",
    "    #print(pd.crosstab(y_test, pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    cm = metrics.confusion_matrix(y_test, pred, labels=class_labels)\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"\\nReport :\")    \n",
    "    print(classification_report(y_test, pred, target_names=class_labels))\n",
    "    \n",
    "    \n",
    "    return clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 A: Naive Bayes Classifier (Tfidf vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Accuracy:   0.749\n",
      "\n",
      "Confusion Matrix :\n",
      "[[ 551  520]\n",
      " [   4 1016]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.99      0.51      0.68      1071\n",
      "       REAL       0.66      1.00      0.79      1020\n",
      "\n",
      "avg / total       0.83      0.75      0.73      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "classify_and_fit(clf, tfidf_train, y_train, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 B: Naive Bayes Classifier (Count vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Accuracy:   0.881\n",
      "\n",
      "Confusion Matrix :\n",
      "[[878 193]\n",
      " [ 56 964]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.94      0.82      0.88      1071\n",
      "       REAL       0.83      0.95      0.89      1020\n",
      "\n",
      "avg / total       0.89      0.88      0.88      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "classify_and_fit(clf, count_train, y_train, count_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Passive Aggressive Classifier (Tfidf vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "Accuracy:   0.938\n",
      "\n",
      "Confusion Matrix :\n",
      "[[1007   64]\n",
      " [  65  955]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.94      0.94      0.94      1071\n",
      "       REAL       0.94      0.94      0.94      1020\n",
      "\n",
      "avg / total       0.94      0.94      0.94      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
       "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
       "              shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "classify_and_fit(linear_clf, tfidf_train, y_train, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Logistic Regression (Tfidf vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy:   0.920\n",
      "\n",
      "Confusion Matrix :\n",
      "[[998  73]\n",
      " [ 95 925]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.91      0.93      0.92      1071\n",
      "       REAL       0.93      0.91      0.92      1020\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression()\n",
    "classify_and_fit(logistic_clf, tfidf_train, y_train, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_names = tfidf_vectorizer.get_feature_names\n",
    "#tokens_with_weights = sorted(list(zip(feature_names, clf.coef_[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve : Use Grid Search to Optimize Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize_fake_news_pipeline(pipeline, X_train, y_train):\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=True)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALPHA = (0.01, 0.05, 0.1) #Tune the Smoothing Parameter for Naive Bayes\n",
    "parameters = {\n",
    "    'tfidf__min_df':np.array([0]),\n",
    "    'tfidf__max_df':np.array([0.7]),\n",
    "    'nb__alpha': ALPHA\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZE: Naive Bayes Pipeline\n",
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'nb']\n",
      "parameters:\n",
      "{'nb__alpha': (0.01, 0.05, 0.1),\n",
      " 'tfidf__max_df': array([ 0.7]),\n",
      " 'tfidf__min_df': array([0])}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 15.526s\n",
      "\n",
      "Best score: 0.893\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.01\n",
      "\ttfidf__max_df: 0.69999999999999996\n",
      "\ttfidf__min_df: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"OPTIMIZE: Naive Bayes Pipeline\\n\")\n",
    "pipelinparameters = {\n",
    "    'tfidf__min_df':np.array([0]),\n",
    "    'tfidf__max_df':np.array([0.7]),\n",
    "    'nb__alpha': ALPHA\n",
    "}e = Pipeline([('tfidf', TfidfVectorizer()), ('nb', MultinomialNB())])\n",
    "optimize_fake_news_pipeline(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = { 'nb__alpha': ALPHA\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZE: Naive Bayes Pipeline\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['count', 'nb']\n",
      "parameters:\n",
      "{'nb__alpha': (0.01, 0.05, 0.1)}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 16.602s\n",
      "\n",
      "Best score: 0.888\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"OPTIMIZE: Naive Bayes Pipeline\\n\")\n",
    "pipeline = Pipeline([('count', CountVectorizer()), ('nb', MultinomialNB())])\n",
    "optimize_fake_news_pipeline(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize: Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZE: Logistic Regression Pipeline\n",
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'logistic']\n",
      "parameters:\n",
      "{'logistic__penalty': ('l1', 'l2'),\n",
      " 'tfidf__max_df': array([ 0.7]),\n",
      " 'tfidf__min_df': array([0])}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   15.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 17.784s\n",
      "\n",
      "Best score: 0.906\n",
      "Best parameters set:\n",
      "\tlogistic__penalty: 'l2'\n",
      "\ttfidf__max_df: 0.69999999999999996\n",
      "\ttfidf__min_df: 0\n"
     ]
    }
   ],
   "source": [
    "PENALTY = ('l1', 'l2')    #Tune for Penalty in Logistic Regression\n",
    "parameters = {\n",
    "    'tfidf__min_df':np.array([0]),\n",
    "    'tfidf__max_df':np.array([0.7]),\n",
    "    'logistic__penalty': PENALTY,\n",
    "}\n",
    "\n",
    "\n",
    "print(\"OPTIMIZE: Logistic Regression Pipeline\\n\")\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer()), ('logistic', LogisticRegression())])\n",
    "optimize_fake_news_pipeline(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize: Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIT_INTERCEPT = (True, False) #Tune for Intercept fitting in Passive Aggressive Classifier\n",
    "parameters = {\n",
    "    'tfidf__min_df':np.array([0]),\n",
    "    'tfidf__max_df':np.array([0.7]),\n",
    "    'passive__fit_intercept':FIT_INTERCEPT    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZE: Passive Aggressive Pipeline\n",
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'passive']\n",
      "parameters:\n",
      "{'passive__fit_intercept': (True, False),\n",
      " 'tfidf__max_df': array([ 0.7]),\n",
      " 'tfidf__min_df': array([0])}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    9.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 11.426s\n",
      "\n",
      "Best score: 0.922\n",
      "Best parameters set:\n",
      "\tpassive__fit_intercept: True\n",
      "\ttfidf__max_df: 0.69999999999999996\n",
      "\ttfidf__min_df: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"OPTIMIZE: Passive Aggressive Pipeline\\n\")\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer()), ('passive', PassiveAggressiveClassifier())])\n",
    "optimize_fake_news_pipeline(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare: Optimized Models for Naive Bayes, Logistic Regression and Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "Accuracy:   0.904\n",
      "\n",
      "Confusion Matrix :\n",
      "[[924 147]\n",
      " [ 54 966]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.94      0.86      0.90      1071\n",
      "       REAL       0.87      0.95      0.91      1020\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1A = MultinomialNB(alpha = 0.01) \n",
    "classify_and_fit(clf_1A, tfidf_train, y_train, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  MultinomialNB(alpha=0.05, class_prior=None, fit_prior=True)\n",
      "Accuracy:   0.904\n",
      "\n",
      "Confusion Matrix :\n",
      "[[936 135]\n",
      " [ 66 954]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.93      0.87      0.90      1071\n",
      "       REAL       0.88      0.94      0.90      1020\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.05, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1B = MultinomialNB(alpha = 0.05)\n",
    "classify_and_fit(clf_1B, count_train, y_train, count_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy:   0.920\n",
      "\n",
      "Confusion Matrix :\n",
      "[[998  73]\n",
      " [ 95 925]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.91      0.93      0.92      1071\n",
      "       REAL       0.93      0.91      0.92      1020\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2 = LogisticRegression(penalty='l2')\n",
    "classify_and_fit(clf_2, tfidf_train, y_train, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier :  PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=5, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "Accuracy:   0.937\n",
      "\n",
      "Confusion Matrix :\n",
      "[[1004   67]\n",
      " [  64  956]]\n",
      "\n",
      "Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.94      0.94      0.94      1071\n",
      "       REAL       0.93      0.94      0.94      1020\n",
      "\n",
      "avg / total       0.94      0.94      0.94      2091\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
       "              loss='hinge', n_iter=5, n_jobs=1, random_state=None,\n",
       "              shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3 = PassiveAggressiveClassifier(fit_intercept=True)\n",
    "classify_and_fit(clf_3, tfidf_train, y_train, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare: Informative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=100):\n",
    "    \"\"\"\n",
    "    See: https://stackoverflow.com/a/26980472\n",
    "    \n",
    "    Identify most important features if given a vectorizer and binary classifier. Set n to the number\n",
    "    of weighted features you would like to show. (Note: current implementation merely prints and does not \n",
    "    return top classes.)\n",
    "    \"\"\"\n",
    "\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "\n",
    "    print()\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print(class_labels[1], coef, feat)\n",
    "    \n",
    "    return topn_class1, topn_class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE -5.67113088514 octob\n",
      "FAKE -5.49568571614 2016\n",
      "FAKE -3.9827836493 share\n",
      "FAKE -3.80541627778 novemb\n",
      "FAKE -3.53490888305 articl\n",
      "FAKE -2.95730636216 sourc\n",
      "FAKE -2.90972086612 elect\n",
      "FAKE -2.83820023232 print\n",
      "FAKE -2.6397580198 howev\n",
      "FAKE -2.2844792595 oct\n",
      "FAKE -2.2712199773 comment\n",
      "FAKE -2.14705069424 pleas\n",
      "FAKE -2.05134224276 wikileak\n",
      "FAKE -2.05010662685 mainstream\n",
      "FAKE -1.97054067113 video\n",
      "FAKE -1.94582997157 post\n",
      "FAKE -1.91824660218 nov\n",
      "FAKE -1.9113633889 email\n",
      "FAKE -1.87920257972 podesta\n",
      "FAKE -1.79691290318 load\n",
      "FAKE -1.79576577288 corrupt\n",
      "FAKE -1.77361594032 28\n",
      "FAKE -1.76939545208 snip\n",
      "FAKE -1.68621466246 vote\n",
      "FAKE -1.65550815423 entir\n",
      "FAKE -1.63163977398 connect\n",
      "FAKE -1.5973490388 hillari\n",
      "FAKE -1.57377561834 min\n",
      "FAKE -1.56899035776 imag\n",
      "FAKE -1.55678531207 url\n",
      "\n",
      "REAL 2.6068026986 conserv\n",
      "REAL 2.45781348786 rush\n",
      "REAL 2.34140621337 monday\n",
      "REAL 2.26148297611 debat\n",
      "REAL 2.16795506615 candid\n",
      "REAL 2.13226775589 gop\n",
      "REAL 2.11692841908 dont\n",
      "REAL 2.07348163174 grow\n",
      "REAL 2.06721250248 messag\n",
      "REAL 2.05411334342 diplomat\n",
      "REAL 2.04688685308 convent\n",
      "REAL 2.04489070488 isnt\n",
      "REAL 2.00342258041 fox\n",
      "REAL 1.98866880574 cnn\n",
      "REAL 1.9825021088 theyr\n",
      "REAL 1.97832914452 requir\n",
      "REAL 1.94069508174 campaign\n",
      "REAL 1.90579345905 israel\n",
      "REAL 1.89509107307 frontrunn\n",
      "REAL 1.88641785989 2013\n",
      "REAL 1.82366861663 httpstcowni9lmsppr\n",
      "REAL 1.81115061347 republican\n",
      "REAL 1.80616247238 drumbeat\n",
      "REAL 1.76935794177 handl\n",
      "REAL 1.76910939706 question\n",
      "REAL 1.75833258368 said\n",
      "REAL 1.74682444724 obama\n",
      "REAL 1.7425104717 contrast\n",
      "REAL 1.73700472505 pick\n",
      "REAL 1.73635103264 wouldnt\n"
     ]
    }
   ],
   "source": [
    "res = most_informative_feature_for_binary_classification(tfidf_vectorizer, linear_clf, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
